{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook performs predictive modeling on the Heart Diseases UCI (https://www.kaggle.com/ronitf/heart-disease-uci) to identify relationship between heart disease and various other features. \n",
    "\n",
    "## Step1:  Select and load python libraries\n",
    "Python libraries loaded to preform the prelimnary EDA include Pandas, Numpy, sklearn, Matplotlb, and Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2:  Load Conditioned Dataset from Exploratory Data Analysis\n",
    "The dataset that was conditioned as part of the Exploratory Data Analysis portion of this project, and saved as a pickel file for use in this phase of the project.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Shape:  (302, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>chest_pain_type</th>\n",
       "      <th>resting_blood_pressure</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>fasting_blood_sugar</th>\n",
       "      <th>rest_ecg</th>\n",
       "      <th>max_heart_rate_achieved</th>\n",
       "      <th>exercise_induced_angina</th>\n",
       "      <th>st_depression</th>\n",
       "      <th>st_slope</th>\n",
       "      <th>num_major_vessels</th>\n",
       "      <th>thalassemia</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender  chest_pain_type  resting_blood_pressure  cholesterol  \\\n",
       "0   63       1                3                     145        233.0   \n",
       "1   37       1                2                     130        250.0   \n",
       "2   41       0                1                     130        204.0   \n",
       "3   56       1                1                     120        236.0   \n",
       "4   57       0                0                     120        354.0   \n",
       "\n",
       "   fasting_blood_sugar  rest_ecg  max_heart_rate_achieved  \\\n",
       "0                    1         0                      150   \n",
       "1                    0         1                      187   \n",
       "2                    0         0                      172   \n",
       "3                    0         1                      178   \n",
       "4                    0         1                      163   \n",
       "\n",
       "   exercise_induced_angina  st_depression  st_slope  num_major_vessels  \\\n",
       "0                        0            2.3         0                  0   \n",
       "1                        0            3.5         0                  0   \n",
       "2                        0            1.4         2                  0   \n",
       "3                        0            0.8         2                  0   \n",
       "4                        1            0.6         2                  0   \n",
       "\n",
       "   thalassemia  target  \n",
       "0            1       1  \n",
       "1            2       1  \n",
       "2            2       1  \n",
       "3            2       1  \n",
       "4            2       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locData=r'C:\\Users\\Lisa\\Documents\\Training\\CoderGirl\\Project\\Data'\n",
    "df=pd.read_pickle(locData+'\\\\heart.pkl')\n",
    "print('Dataframe Shape:  {}'.format(df.shape))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3:  Reorder data set\n",
    "The dataset appears to be orgainized in such a way that the patients that have heart disease are listed first, followed by the patients that do not have heart disease.  The dataframe was shuffled such that the heart disease target column was randomly ordered, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>chest_pain_type</th>\n",
       "      <th>resting_blood_pressure</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>fasting_blood_sugar</th>\n",
       "      <th>rest_ecg</th>\n",
       "      <th>max_heart_rate_achieved</th>\n",
       "      <th>exercise_induced_angina</th>\n",
       "      <th>st_depression</th>\n",
       "      <th>st_slope</th>\n",
       "      <th>num_major_vessels</th>\n",
       "      <th>thalassemia</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>319.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>180</td>\n",
       "      <td>274.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>243.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender  chest_pain_type  resting_blood_pressure  cholesterol  \\\n",
       "0   42       1                2                     130        180.0   \n",
       "1   58       0                1                     136        319.0   \n",
       "2   68       1                2                     180        274.0   \n",
       "3   62       0                0                     138        294.0   \n",
       "4   47       1                2                     108        243.0   \n",
       "\n",
       "   fasting_blood_sugar  rest_ecg  max_heart_rate_achieved  \\\n",
       "0                    0         1                      150   \n",
       "1                    1         0                      152   \n",
       "2                    1         0                      150   \n",
       "3                    1         1                      106   \n",
       "4                    0         1                      152   \n",
       "\n",
       "   exercise_induced_angina  st_depression  st_slope  num_major_vessels  \\\n",
       "0                        0            0.0         2                  0   \n",
       "1                        0            0.0         2                  2   \n",
       "2                        1            1.6         1                  0   \n",
       "3                        0            1.9         1                  3   \n",
       "4                        0            0.0         2                  0   \n",
       "\n",
       "   thalassemia  target  \n",
       "0            2       1  \n",
       "1            2       0  \n",
       "2            3       0  \n",
       "3            2       0  \n",
       "4            2       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfReOrdered=df.sample(frac=1).reset_index(drop=True)\n",
    "dfReOrdered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4:  Seperate the predictor and response variables.\n",
    "The response variable (i.e. what we are trying to predict) is the target column of the dataframe, and the predictor variables (i.e. variables used to predict) are the other columns of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: target, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>chest_pain_type</th>\n",
       "      <th>resting_blood_pressure</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>fasting_blood_sugar</th>\n",
       "      <th>rest_ecg</th>\n",
       "      <th>max_heart_rate_achieved</th>\n",
       "      <th>exercise_induced_angina</th>\n",
       "      <th>st_depression</th>\n",
       "      <th>st_slope</th>\n",
       "      <th>num_major_vessels</th>\n",
       "      <th>thalassemia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>319.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>180</td>\n",
       "      <td>274.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>243.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender  chest_pain_type  resting_blood_pressure  cholesterol  \\\n",
       "0   42       1                2                     130        180.0   \n",
       "1   58       0                1                     136        319.0   \n",
       "2   68       1                2                     180        274.0   \n",
       "3   62       0                0                     138        294.0   \n",
       "4   47       1                2                     108        243.0   \n",
       "\n",
       "   fasting_blood_sugar  rest_ecg  max_heart_rate_achieved  \\\n",
       "0                    0         1                      150   \n",
       "1                    1         0                      152   \n",
       "2                    1         0                      150   \n",
       "3                    1         1                      106   \n",
       "4                    0         1                      152   \n",
       "\n",
       "   exercise_induced_angina  st_depression  st_slope  num_major_vessels  \\\n",
       "0                        0            0.0         2                  0   \n",
       "1                        0            0.0         2                  2   \n",
       "2                        1            1.6         1                  0   \n",
       "3                        0            1.9         1                  3   \n",
       "4                        0            0.0         2                  0   \n",
       "\n",
       "   thalassemia  \n",
       "0            2  \n",
       "1            2  \n",
       "2            3  \n",
       "3            2  \n",
       "4            2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=dfReOrdered.target\n",
    "print(y[:5])\n",
    "x=dfReOrdered.drop('target',axis=1)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5:  Seperate the dataset into training and test groups, and standardize the x-dataframe\n",
    "\n",
    "The training and test groups were selected using the train_test_split function in the sklearn model_selection tool box.  Note, a validation group was not selected for this analysis, as there was a limited amount of data and when GridSearchCV was implemented in Step 7 of this effort a cross-validation technique was implemented for hyperparameter tuning.\n",
    "\n",
    "The min-max scaler from the sklearn pre-processing toolbox was selected for feature standardization.  This was selected over the standard normal standardization as not all features appeared to be normally distributed when visually inspected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lisa\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y)\n",
    "\n",
    "scaler=MinMaxScaler().fit(xtrain)\n",
    "xtrainScaled=scaler.transform(xtrain) \n",
    "xtestScaled=scaler.transform(xtest) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6:  Evaluate commonly used binary classifiers\n",
    "Several commonly used binary classifiers were evaluated with default parameters to determine which predictive model may require the least amount of tuning to achieve the most accurate heart disease predictive model.\n",
    "\n",
    "The random forest classification algorithim was selected for use as a predictive model for this project, as it is commonly used and has a top accuracy score (i.e. accuracy = 0.83).  Note, the Extra Tree Classification model has the highest accuracy score (i.e. accuracy = 0.84); however, it is less widely used than the random forest algorithm and accordingly was not selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression : 0.7763157894736842\n",
      "Decision Tree Classification : 0.7763157894736842\n",
      "Random Forest Classification : 0.7631578947368421\n",
      "Gradient Boosting Classification :"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lisa\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Lisa\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.7236842105263158\n",
      "Ada Boosting Classification : 0.75\n",
      "Extra Tree Classification : 0.8289473684210527\n",
      "K-Neighbors Classification : 0.8026315789473685\n",
      "Support Vector Classification : 0.7368421052631579\n",
      "Gaussian Naive Bayes : 0.7894736842105263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lisa\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Lisa\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "classifiers=[['Logistic Regression :',LogisticRegression()],\n",
    "       ['Decision Tree Classification :',DecisionTreeClassifier()],\n",
    "       ['Random Forest Classification :',RandomForestClassifier()],\n",
    "       ['Gradient Boosting Classification :', GradientBoostingClassifier()],\n",
    "       ['Ada Boosting Classification :',AdaBoostClassifier()],\n",
    "       ['Extra Tree Classification :', ExtraTreesClassifier()],\n",
    "       ['K-Neighbors Classification :',KNeighborsClassifier()],\n",
    "       ['Support Vector Classification :',SVC()],\n",
    "       ['Gaussian Naive Bayes :',GaussianNB()]]\n",
    "\n",
    "cla_pred=[]\n",
    "\n",
    "for name,model in classifiers:\n",
    "    \n",
    "    model=model\n",
    "    model.fit(xtrainScaled,ytrain)\n",
    "    predictions = model.predict(xtestScaled)\n",
    "    cla_pred.append(accuracy_score(ytest,predictions))\n",
    "    print(name,accuracy_score(ytest,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7:  Tune the random forest algorithm for optimal preformance\n",
    "To identify the most influential hyper-parameters for tuning a random forest classifier, several blog post and articles were reviewed, and the most influenital hyper-parameters identified, included:  max_features, n_estimators, max_depth, min_sample_leaf, and criterion.  Accordinlgy, a grid search was developed to ideintify the optimal input value for each of the most influential hyper-parameters.  The optimal values are shown below.\n",
    "\n",
    "References:\n",
    "https://stackoverflow.com/questions/36107820/how-to-tune-parameters-in-random-forest-using-scikit-learn\n",
    "https://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/\n",
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "https://www.kaggle.com/hadend/tuning-random-forest-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lisa\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 9,\n",
       " 'min_samples_leaf': 4,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=RandomForestClassifier()\n",
    "paramGrid=[{'n_estimators':[50,100,200],'max_depth':[3,5,7,9],\n",
    "           'min_samples_leaf':[1,2,4],'criterion':['gini','entropy']}]\n",
    "gridSearch=GridSearchCV(model,paramGrid,cv=5)\n",
    "gridSearch.fit(xtrainScaled,ytrain)\n",
    "gridSearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8:  Execute the model\n",
    "Once the optimal parameter values were identified from the GridSearchCV function, a model was developed using the selected values, as shown below.  Also, accuracy, sensitiviy, and specificity were also computed model metrics.  \n",
    "\n",
    "In general, the model is over-trained as indicated by the difference of 0.12 in accuracy between the training and test model accuracies.  \n",
    "\n",
    "Sensitivity refers to the correctly identfied true positives.  For this case, approximately 80 percent were idenitfied correctly.  Specificity refers to the models ability to identify true negatives, like sensitivity, approximately 80 percent were correctly identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy : 0.9380530973451328\n",
      "Testing Accuracy : 0.7894736842105263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.62      0.74        37\n",
      "           1       0.73      0.95      0.82        39\n",
      "\n",
      "   micro avg       0.79      0.79      0.79        76\n",
      "   macro avg       0.82      0.79      0.78        76\n",
      "weighted avg       0.82      0.79      0.78        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=RandomForestClassifier(criterion='gini',max_depth=5,min_samples_leaf=2,n_estimators=100)\n",
    "model.fit(xtrainScaled,ytrain)\n",
    "yhat=model.predict(xtestScaled)\n",
    "yhat_quant=model.predict_proba(xtestScaled)[:, 1]\n",
    "yhat_bin=model.predict(xtestScaled)\n",
    "print(\"Training Accuracy :\", model.score(xtrainScaled,ytrain))\n",
    "print(\"Testing Accuracy :\", model.score(xtestScaled,ytest))\n",
    "\n",
    "cr=classification_report(ytest,yhat)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23, 14],\n",
       "       [ 2, 37]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix=confusion_matrix(ytest,yhat_bin)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity :  0.92\n",
      "Specificity :  0.7254901960784313\n"
     ]
    }
   ],
   "source": [
    "total=sum(sum(confusion_matrix))\n",
    "\n",
    "sensitivity = confusion_matrix[0,0]/(confusion_matrix[0,0]+confusion_matrix[1,0])\n",
    "print('Sensitivity : ', sensitivity )\n",
    "\n",
    "specificity = confusion_matrix[1,1]/(confusion_matrix[1,1]+confusion_matrix[0,1])\n",
    "print('Specificity : ', specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9:  Save model for next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename='finalized_model.sav'\n",
    "\n",
    "xtrainScaled=pd.DataFrame(xtrainScaled,columns=xtrain.columns)\n",
    "xtestScaled=pd.DataFrame(xtestScaled,columns=xtrain.columns)\n",
    "\n",
    "pickle.dump([model,confusion_matrix,xtrainScaled,ytrain,xtestScaled,ytest,yhat_quant],open(locData+'\\\\'+filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
